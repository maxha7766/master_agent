/**
 * Test script to verify all added models work correctly
 * Tests each model with a simple chat completion request
 */

import OpenAI from 'openai';
import Anthropic from '@anthropic-ai/sdk';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

const TEST_PROMPT = 'Say "Hello! I am working correctly." in exactly that format.';

// All working models (tested and verified)
const MODELS_TO_TEST = {
  anthropic: [
    'claude-sonnet-4-5-20250929',
    'claude-3-haiku-20240307',
  ],
  openai: {
    gpt5: [
      'gpt-5.1',
      'gpt-5',
      'gpt-5-mini',
      'gpt-5-nano',
    ],
    gpt4: [
      'gpt-4o',
      'gpt-4o-mini',
      'gpt-4-turbo',
      'gpt-4',
      'gpt-3.5-turbo',
    ],
    reasoning: [
      'o1',
    ],
  },
};

const results = {
  passed: [],
  failed: [],
};

/**
 * Test an Anthropic model
 */
async function testAnthropicModel(model) {
  try {
    console.log(`\nðŸ§ª Testing ${model}...`);

    const response = await anthropic.messages.create({
      model,
      max_tokens: 100,
      messages: [{ role: 'user', content: TEST_PROMPT }],
    });

    const content = response.content[0]?.text || '';

    console.log(`âœ… ${model} - SUCCESS`);
    console.log(`   Response: ${content}`);
    console.log(`   Tokens: ${response.usage.input_tokens} input, ${response.usage.output_tokens} output`);

    results.passed.push({
      model,
      provider: 'anthropic',
      response: content,
      tokens: response.usage,
    });

    return true;
  } catch (error) {
    console.log(`âŒ ${model} - FAILED`);
    console.log(`   Error: ${error.message}`);

    results.failed.push({
      model,
      provider: 'anthropic',
      error: error.message,
      errorType: error.constructor.name,
    });

    return false;
  }
}

/**
 * Test an OpenAI model with standard Chat Completions API
 */
async function testOpenAIModel(model, useTemperature = true) {
  try {
    console.log(`\nðŸ§ª Testing ${model}...`);

    const isGPT5 = model.startsWith('gpt-5');
    const isO1 = model.startsWith('o1');
    const useNewParams = isGPT5 || isO1;

    const params = {
      model,
      messages: [{ role: 'user', content: TEST_PROMPT }],
    };

    // GPT-5 and o1 models use max_completion_tokens instead of max_tokens
    if (useNewParams) {
      params.max_completion_tokens = 100;
      // Don't add temperature or top_p
    } else {
      params.max_tokens = 100;
      if (useTemperature) {
        params.temperature = 0.7;
      }
    }

    const response = await openai.chat.completions.create(params);

    const content = response.choices[0]?.message?.content || '';

    console.log(`âœ… ${model} - SUCCESS`);
    console.log(`   Response: ${content}`);
    console.log(`   Tokens: ${response.usage?.prompt_tokens || 0} input, ${response.usage?.completion_tokens || 0} output`);

    results.passed.push({
      model,
      provider: 'openai',
      response: content,
      tokens: response.usage,
    });

    return true;
  } catch (error) {
    console.log(`âŒ ${model} - FAILED`);
    console.log(`   Error: ${error.message}`);

    // If temperature error, retry without it
    if (error.message.includes('temperature') && useTemperature) {
      console.log(`   ðŸ”„ Retrying without temperature parameter...`);
      return await testOpenAIModel(model, false);
    }

    results.failed.push({
      model,
      provider: 'openai',
      error: error.message,
      errorType: error.constructor.name,
    });

    return false;
  }
}

/**
 * Main test runner
 */
async function runTests() {
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('ðŸš€ TESTING ALL ADDED MODELS');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

  // Test Anthropic models
  console.log('\n\nðŸ“˜ TESTING ANTHROPIC MODELS');
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  for (const model of MODELS_TO_TEST.anthropic) {
    await testAnthropicModel(model);
    await new Promise(resolve => setTimeout(resolve, 1000)); // Rate limiting
  }

  // Test GPT-5 models (no temperature support)
  console.log('\n\nðŸ“— TESTING GPT-5 SERIES');
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  for (const model of MODELS_TO_TEST.openai.gpt5) {
    await testOpenAIModel(model, false);
    await new Promise(resolve => setTimeout(resolve, 1000));
  }

  // Test GPT-4 models (with temperature support)
  console.log('\n\nðŸ“™ TESTING GPT-4 SERIES');
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  for (const model of MODELS_TO_TEST.openai.gpt4) {
    await testOpenAIModel(model, true);
    await new Promise(resolve => setTimeout(resolve, 1000));
  }

  // Test reasoning models (no temperature support)
  console.log('\n\nðŸ“• TESTING REASONING MODELS (o-series)');
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  for (const model of MODELS_TO_TEST.openai.reasoning) {
    await testOpenAIModel(model, false);
    await new Promise(resolve => setTimeout(resolve, 1000));
  }

  // Print summary
  console.log('\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('ðŸ“Š TEST SUMMARY');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

  console.log(`\nâœ… PASSED: ${results.passed.length} models`);
  results.passed.forEach(result => {
    console.log(`   â€¢ ${result.model} (${result.provider})`);
  });

  console.log(`\nâŒ FAILED: ${results.failed.length} models`);
  results.failed.forEach(result => {
    console.log(`   â€¢ ${result.model} (${result.provider})`);
    console.log(`     Error: ${result.error}`);
  });

  console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

  // Exit with error code if any tests failed
  if (results.failed.length > 0) {
    console.log('\nâš ï¸  Some models failed testing. Review the errors above.');
    process.exit(1);
  } else {
    console.log('\nðŸŽ‰ All models passed testing!');
    process.exit(0);
  }
}

// Run tests
runTests().catch(error => {
  console.error('\nðŸ’¥ Fatal error during testing:', error);
  process.exit(1);
});
